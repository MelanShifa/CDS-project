{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' We used the ipynb file for dev purposes to make the flow easier'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xlrd\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_reader(level):\n",
    "    '''Data reader takes level as an input, for now we have parsed the undergraduate classes only, and takes the Separetedfile.xlsx file and stores it as a dataframe df'''\n",
    "    df = pd.read_excel('Separetedfile.xlsx', sheet_name=\"PreReqText Courses\")\n",
    "    df = df[df['CourseLevel'] == level.title()]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' The functions named manually cleaned below, are used to get the last 1.7 % on parsing success rate. These classes are manually parsed due to their extreme complications'''\n",
    "def math_manually_cleaned(column, df):\n",
    "    df[column] = df[column].apply(lambda x: re.sub(\"\\s+\", \" \", x))\n",
    "    df[column] = df[column].apply(lambda x: re.sub(' \\(MATH 354, STATS 354, MATH 455 or STAT 455\\) and MATH 223',\n",
    "                                  '( MATH 354 or STATS 354 or MATH 455 or STAT 455 ) and MATH 223', x))\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ANTH_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\n",
    "        \"GEOG 101, ANTH 210; Students are strongly encouraged to take Geog 315 or 4/515 before enrolling. Geol 121 can be substituted for Geog 101 with instructor permission.\", \"GEOG 101, ANTH 210\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def BIO_manually_cleaned(column, df):\n",
    "    df[column] = df[column].apply(lambda x: x.strip())\n",
    "    df[column] = df[column].replace(\"One BIOL course and one semester of chemistry from among CHEM 104, CHEM 106, CHEM 111, or CHEM 201\",\n",
    "                                    \"BIO COURSE, CHEM 104 OR CHEM 106 OR CHEM 111 OR CHEM 201\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def CHEM_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\n",
    "        \"Student must demonstrate math placement requirements at or above MATH 112 in the placement chart. See Mathematics for details.\", \"\")\n",
    "    df[column] = df[column].replace(\n",
    "        'High school chemistry or “C” (2.0) or higher in CHEM 104. Student must demonstrate math placement requirements at or above MATH 115 in the placement chart. See Mathematics for details.', 'CHEM 104')\n",
    "    df[column] = df[column].str.replace(\n",
    "    r'\\bBIOL 106,\\s+CHEM 324\\.\\s*BIOL 106 or permission “C” \\(2\\.0\\) or higher in all prerequisites\\.', \n",
    "    'BIOL 106, CHEM 324', regex=True)\n",
    "    df[column] = df[column].replace(\n",
    "    r'\\bConcurrent registration in CHEM 460 or completion of CHEM 460 with “C” or higher\\. CHEM 305 is highly recommended\\. ',\n",
    "    '', regex=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def CS_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\"CS 491 and (CS 306, CS 401, CS 403, CS 406, CS 410, CS 420, CS 435, CS 440, CS 445, CS 450, CS 465, CS 470, CS 480, or CS 485)\",\n",
    "                                    \"CS 491 and CS 306 or CS 401 or CS 403 or CS 406 or CS 410 or CS 420 or CS 435 or CS 440 or CS 445 or CS 450 or CS 465 or CS 470 or CS 480 or CS 485 )\")\n",
    "    df[column] = df[column].replace(\"CS 491W and (CS 306, CS 401, CS 403, CS 406, CS 410, CS 420, CS 435, CS 440, CS 445, CS 450, CS 465, CS 470, CS 480, or CS 485)\",\n",
    "                                    \"CS 491W and CS 306 or CS 401 or CS 403 or CS 406 or CS 410 or CS 420 or CS 435 or CS 440 or CS 445 or CS 450 or CS 465 or CS 470 or CS 480 or CS 485 )\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def CDIS_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\"3 of the following: 402, 417, 438. CDIS 416 is recommended.\",\n",
    "                                    \"CDIS 402 and CDIS 417 and CDIS 438\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def EE_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\"EE, 230, EE 231, EE 240\",\n",
    "                                    \"EE 230, EE 231, EE 240\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def GEOG_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\"Prerequisite: GEOG 373, or 473/573, or permission of instructor.\",\n",
    "                                    \"Prerequisite: GEOG 373, or GEOG 473 or GEOG 573, or permission of instructor.\")\n",
    "    df[column] = df[column].replace(\"Either Geog 101 or Geol 121 and Geog 315 or 415 are recommended. Or instructor consent.\",\n",
    "                                    \"Either Geog 101 or Geol 121 and Geog 315 or Geog 415 are recommended. Or instructor consent.\")\n",
    "    df[column] = df[column].replace(\n",
    "        \"Either GEOG 101 or ANTH 210; We strongly encourage students to take GEOG 315 before enrolling. Geol 121 can be substituted for GEOG 101 with instructor permission.\", \"Either GEOG 101 or ANTH 210\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def GEOL_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\"CHEM 191, CHEM 201, GEOL/BIOL 104 or instructor permission.\",\n",
    "                                    \"CHEM 191, CHEM 201, GEOL 104 or BIOL 104 or instructor permission.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MATH_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\n",
    "        \"Three years high school algebra/geometry or MATH 098\", \"MATH 098\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MET_manually_cleaned(column, df):\n",
    "    df[column] = df[column].replace(\n",
    "        \"ENG 271W, MET 275, MET 425, 10 AET or MET 300/400 level credits\", \"ENG 271W, MET 275, MET 425\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def STAT_manually_cleaned(column, df):\n",
    "    df[column] = df[column].str.replace(\n",
    "        \"MATH/STAT 354\", \"MATH 354 or STAT 354\")\n",
    "    df[column] = df[column].str.replace(\n",
    "        \"MATH 354 or STAT 354 or both MATH 121 and STAT 154\", \"MATH 354 or STAT 354 or both STAT 154 and MATH 121\")\n",
    "    df[column] = df[column].str.replace(\n",
    "        \"MATH 354 or STAT 354 or both MATH 121 adn STAT 154\", \"MATH 354 or STAT 354 or both STAT 154 adn MATH 121\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def RPLS_manually_cleaned(column, df):\n",
    "    df[column] = df[column].str.replace(\"RPLS 272 RPLS 282 RPLS 341W, or with instructor permission. Upper division prerequisites can be taken concurrently with instructor permission.\",\n",
    "                                        \"RPLS 272, RPLS 282, RPLS 341W, or with instructor permission. Upper division prerequisites can be taken concurrently with instructor permission.\", regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def PSYC_manually_cleaned(column, df):\n",
    "    df[column] = df[column].str.replace(\"Complete one course: MATH 112, MATH 113, MATH 115, MATH 121, MATH 130, or STAT 154\",\n",
    "                                        \"MATH 112 or MATH 113 or MATH 115 or MATH 121 or MATH 130 or STAT 154\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def choose_two_manually_cleaned(column, df):\n",
    "    df[column] = df[column].str.replace(\"Two of the following: MATH 316, MATH 321, MATH 345, MATH 375 and senior standing \\(or permission of the instructor\\). Course can also be taken independent study with permission of a cooperating faculty member.\",\n",
    "                                        \"MATH 316 or MATH 321 or MATH 345 or MATH 375 AND MATH 316 or MATH 321 or MATH 345 or MATH 375\", regex=True)\n",
    "    df[column] = df[column].str.replace(\"STAT 457, STAT 458, STAT 459, STAT 450 \\(at least two of these\\)\",\n",
    "                                        \"STAT 457 or STAT 458 or STAT 459 or STAT 450 AND STAT 457 or STAT 458 or STAT 459 or STAT 450\", regex=True)\n",
    "    df[column] = df[column].str.replace(\"IBUS 428, IBUS 448, IBUS 469 \\(select 2 out of the 3 courses\\)\",\n",
    "                                        \"IBUS 428 or IBUS 448 or IBUS 469 AND IBUS 428 or IBUS 448 or IBUS 469\", regex=True)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_formatter(column, df):\n",
    "    '''Takes the data frame and works on the PreReqText column, focusing on the ORs to have a consistent structure '''\n",
    "    df[column] = df[column].str.replace(' / |/', ' or ', regex=True)\n",
    "    df[column] = df[column].str.replace(', or', ' or')\n",
    "    df[column] = df[column].str.replace('OR \"C\"', 'or C')\n",
    "    df[column] = df[column].str.replace(', with ', ' with ')\n",
    "    df[column] = df[column].str.replace(', and', ' and')\n",
    "    df[column] = df[column].str.replace('\\(or ', '( or ', regex=True)\n",
    "    df[column] = df[column].str.replace('OR', 'or')\n",
    "    df[column] = df[column].str.replace('or better', '', regex=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def or_and_formatter_2(column, df):\n",
    "    '''Focuses on the ANDs to have a consistent structure '''\n",
    "\n",
    "    df[column] = df[column].str.replace('Select One:|Select 1:','and',  flags=re.IGNORECASE, regex=True)\n",
    "    df[column] = df[column].str.replace('.', ' and ', regex=True)\n",
    "    df[column] = df[column].str.replace('&', ' and ')\n",
    "    df[column] = df[column].str.replace(';', ' and ')\n",
    "    df[column] = df[column].str.replace(' AND ', ' and ', regex=True)\n",
    "    df[column] = df[column].str.replace(' adn ', ' and ')\n",
    "    df[column] = df[column].str.replace(',| , ', ' and ', regex=True)\n",
    "    df[column] = df[column].str.replace('(', '(  ', regex=True)\n",
    "    df[column] = df[column].str.replace(')', ' )', regex=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def typo_fixer(column, df):\n",
    "    ''' Fixes Typos in the data-frame'''\n",
    "    df[column] = df[column].str.replace(\"ATHN\", \"ETHN\")\n",
    "    df[column] = df[column].str.replace(\"DANC120W\", \"DANC 120W\")\n",
    "    df[column] = df[column].str.replace(\"STATS\", \"STAT\")\n",
    "    df[column] = df[column].str.replace(\"CDS\", \"CDIS\")\n",
    "    df[column] = df[column].str.replace(\"ACT\", \"ACCT\")\n",
    "    df[column] = df[column].str.replace(\"MUS \", \"MUSC \")\n",
    "    df[column] = df[column].str.replace(\"Psy \", \"PSYC \")\n",
    "    df[column] = df[column].str.replace(\"SPC \", \"SOC \")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_before_strongly_recommended(column):\n",
    "    '''temporarily: We are removing all non class PreReqs '''\n",
    "    pattern = re.compile(r'(?:[A-Z]+\\s\\d+\\W*\\s*,\\s*)*([A-Z]+\\s\\d+\\W*)*\\W*(strongly recommended|recommended|is strongly recommended|advisory)', flags=re.IGNORECASE)\n",
    "    return column.apply(lambda x: re.sub(pattern, '', x, count=1))\n",
    "\n",
    "\n",
    "\n",
    "def remove_after_point(column, point):\n",
    "    ''' Some classes which are supposed to be in the concurrent sheet are listed under PreReq, so we are removing them here'''\n",
    "    class_lists = column.apply(lambda x: x.upper().split(\" \"))\n",
    "    new_lists = []\n",
    "    pattern = re.compile(r'\\b(CONCURRENT|CURRENTLY)\\w*\\b', flags=re.IGNORECASE)\n",
    "    for class_list in class_lists:\n",
    "        new_class_list = []\n",
    "        for word in class_list:\n",
    "            if pattern.search(word):\n",
    "                new_class_list.append('CO-REQUISITE:')\n",
    "            else:\n",
    "                new_class_list.append(word)\n",
    "        if point in new_class_list:\n",
    "            index = new_class_list.index(point)\n",
    "            new_class_list = new_class_list[:index-1]\n",
    "        new_lists.append(new_class_list)\n",
    "    new_column = []\n",
    "    for new_list in new_lists:\n",
    "        new_column.append(\" \".join(new_list))\n",
    "    return new_column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_class_list(class_list, sub):\n",
    "    ''' This function comes after the parser function, it cleans the data from trailing or leading extra words'''\n",
    "    i = 0\n",
    "    while i < len(class_list):\n",
    "        if class_list[i] == 'OR':\n",
    "            # Remove non-class elements following \"OR\"\n",
    "            j = i + 1\n",
    "            while j < len(class_list) and class_list[j] not in sub:\n",
    "                class_list.pop(j)\n",
    "            if j < len(class_list):\n",
    "                i = j\n",
    "            else:\n",
    "                break\n",
    "        elif class_list[i] in sub and (i == len(class_list) - 1 or not (len(class_list[i+1]) == 3 and class_list[i+1].isdigit() or len(class_list[i+1]) == 4 and class_list[i+1][:3].isdigit() and class_list[i+1][3] == 'W')):\n",
    "            class_list.pop(i)\n",
    "        else:\n",
    "            i += 1\n",
    "    # Remove leading and trailing \"or\" and \"and\" conjunctions\n",
    "    while class_list and class_list[0] in [\"OR\",\"AND\",\" OR \",\" AND \"]:\n",
    "        class_list = class_list[1:]\n",
    "    while class_list and class_list[-1] in [\"OR\",\"AND\",\" OR \",\" AND \"]:\n",
    "        class_list = class_list[:-1]\n",
    "    # Remove classes that are not followed by numbers\n",
    "    return class_list\n",
    "\n",
    "\n",
    "def parser_function(column, df):\n",
    "    '''This is the main part of the algorithm, it removes every word that isn't an instance of the class or our conjunction points'''\n",
    "    df[column] = df[column].str.replace('\\.\\s*$', '', regex=True)\n",
    "    df[column] = df[column].apply(lambda x: x.upper().split(\" \"))\n",
    "    conjunction=[\"OR\",\"AND\",\" OR \",\" AND \"]\n",
    "    sub=df[\"SubjectAbbreviation\"].tolist()\n",
    "    sub.extend([\"IT\",\"ISYS\", \"CJ\"])\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        new_list = []\n",
    "        for i in row[column]:\n",
    "            if i in sub or i in conjunction or (isinstance(i, str) and ((len(i) == 3 and i.isdigit()) or (len(i) == 4 and i[:3].isdigit() and i[3] == 'W'))):\n",
    "                new_list.append(i)\n",
    "            else:\n",
    "                continue\n",
    "        new_list = clean_class_list(new_list, sub)\n",
    "        df.at[index, column] = \" \".join(new_list)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def And_formatter_for_separation(column, df):\n",
    "    '''This function formats AND to comma for our separation to begin'''\n",
    "    df[column] = df[column].str.replace(\" AND \", \" , \")\n",
    "    return df\n",
    "\n",
    "def credit_300(column, df):\n",
    "    '''We have a couple of words that say 300 credit level which aren't need within our algorithm for now, so this removes the number 300 that is left off from our parser function'''\n",
    "    df[column] = df[column].apply(lambda x: x.upper().split(\" \"))\n",
    "    sub = df[\"SubjectAbbreviation\"].tolist()\n",
    "    sub.extend([\"IT\",\"ISYS\", \"CJ\"])\n",
    "    for index, row in df.iterrows():\n",
    "        new_list = []\n",
    "        for i in range(len(row[column])):\n",
    "            if row[column][i] == \"300\" and (row[column][i-1] not in sub):\n",
    "                continue\n",
    "            else:\n",
    "                new_list.append(row[column][i])\n",
    "        df.at[index, column] = \" \".join(new_list)\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_comma_count(df):\n",
    "    ''' The two functions below creates new columns based on how much is needed to make ready for our next step which is splitting the prerequisites into separate columns from the PreReqText column.\n",
    "        The first function creates the columns by taking the largest number of prereqs from the second function. \n",
    "        The second function determines how many new columns are needed by counting the number of prereqs in each cell of the column and storing the value of prereqs for the cell with the largest number of prereqs. It does this by counting the commas, (commas are the separator of prereqs.)'''\n",
    "    prereqs = 0\n",
    "    for i in df[\"PreReqText\"]:\n",
    "        count = 0\n",
    "        x=\",\"\n",
    "        for j in i:\n",
    "            if j == x:\n",
    "                count+=1\n",
    "        if count>prereqs:\n",
    "            prereqs=count\n",
    "    return prereqs+1\n",
    "\n",
    "\n",
    "def create_new_columns(df, prereqs):\n",
    "    for i in range(prereqs):\n",
    "        df[\"Prereq \" + str(i + 1)] = \"\"\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_values_into_columns(df, y):\n",
    "    '''The code below will split the values into the newly created columns.'''\n",
    "    last_y_columns = df.columns[-y:]\n",
    "    for i, row in df.iterrows():\n",
    "        split_values = row[\"PreReqText\"].split(\",\")\n",
    "        for j in range(y):\n",
    "            if j < len(split_values):\n",
    "                df.at[i, last_y_columns[j]] = split_values[j]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_array_split(df):\n",
    "    '''The code below removes unsolved instance of AND due to duplication, and creates the inner OR array'''\n",
    "    subjects= df['SubjectAbbreviation'].drop_duplicates().tolist()\n",
    "    columns_to_replace = df.columns[df.columns.get_loc(\"CourseLevel\") + 1:]  \n",
    "    df.loc[:, columns_to_replace] = df.loc[:, columns_to_replace].apply(lambda x: x.str.replace(r'^OR\\s*', '', regex=True))\n",
    "    df.loc[:, columns_to_replace] = df.loc[:, columns_to_replace].apply(lambda x: x.str.replace('AND', '', regex=True))\n",
    "    df.loc[:, columns_to_replace] = df.loc[:, columns_to_replace].apply(lambda x: x.str.strip())  \n",
    "\n",
    "    for col in columns_to_replace:\n",
    "        df[col] = df[col].apply(lambda x: x.split(\" OR \") if isinstance(x, str) and \" OR \" in x else x)\n",
    "\n",
    "    return df  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_creator(df, filename):\n",
    "    '''The code below converts the values into a dictionary and exports them as a json file, so we could be able to use it for our tree algorithm.'''\n",
    "    columns_to_replace = df.columns[df.columns.get_loc(\"CourseLevel\") + 1:]    \n",
    "    df[\"key\"] = df[\"SubjectAbbreviation\"] + \" \" + df[\"CourseNumber\"].map(str)\n",
    "    columns_to_include = ['key']\n",
    "    columns_to_include.extend(columns_to_replace)\n",
    "    df=df[columns_to_include]\n",
    "    d={}\n",
    "    for i, row in df.iterrows():\n",
    "            class_name=row['key']\n",
    "            values = []\n",
    "            for cell_value in row[columns_to_include[1:]]:\n",
    "                if cell_value not in ['', None]:\n",
    "                    values.append(cell_value)\n",
    "            if values:\n",
    "                d[class_name] = values\n",
    "\n",
    "    json_string = json.dumps(d, ensure_ascii=False, separators=(',', ': '))\n",
    "    json_string = json_string.replace('],\"', '],\\n\"').replace('{', '{\\n').replace('}', '\\n}')\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_column(df, json_file):\n",
    "    '''The function creates a Json column for testing purposes'''\n",
    "    with open(json_file, 'r') as f:\n",
    "        json_data = f.read()\n",
    "    data = json.loads(json_data)\n",
    "    \n",
    "    json_col = []\n",
    "    for i, row in df.iterrows():\n",
    "        key = row['SubjectAbbreviation'] + ' ' + str(row['CourseNumber'])\n",
    "        if key in data:\n",
    "            json_col.append(data[key])\n",
    "        else:\n",
    "            json_col.append([])\n",
    "    df['Json format'] = json_col\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(json_file_path, df):\n",
    "    '''The function calculates how many percent of the data was successfully parsed'''\n",
    "    code_pattern = re.compile(r\"^[A-Z]{1,4}\\s\\d{3}W?\\s?$\")\n",
    "    subjects = df['SubjectAbbreviation'].drop_duplicates().tolist()\n",
    "    subjects.extend([\"IT\",\"ISYS\", \"CJ\"])\n",
    "\n",
    "    with open(json_file_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    num_successful = 0\n",
    "    num_unsuccessful = 0\n",
    "    unsuccess = []\n",
    "\n",
    "    def is_successful_value(value):\n",
    "        if isinstance(value, list):\n",
    "            for element in value:\n",
    "                if isinstance(element, list):\n",
    "                    if not all(is_successful_value(nested_element) for nested_element in element):\n",
    "                        return False\n",
    "                else:\n",
    "                    if not any(subject in element for subject in subjects) or not code_pattern.match(element):\n",
    "                        return False\n",
    "            return True\n",
    "        else:\n",
    "            return any(subject in value for subject in subjects) and code_pattern.match(value)\n",
    "\n",
    "    for value in data.values():\n",
    "        if is_successful_value(value):\n",
    "            num_successful += 1\n",
    "        else:\n",
    "            num_unsuccessful += 1\n",
    "            unsuccess.append(value)\n",
    "\n",
    "\n",
    "    total_rows = num_successful + num_unsuccessful\n",
    "    success_rate = num_successful / total_rows * 100\n",
    "    x = \"{:.2f}\".format(success_rate)\n",
    "    #print(unsuccess) -> uncomment for debugging \n",
    "    return x +\" percent successfully parsed\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['CHEM 202', 'OR CHEM 202'], ['MATH 110', 'STAT 154', 'OR MATH 110'], ['500'], ['MASS 221W', 'MASS 312', 'MASS 411', 'OR', 'MASS 325', 'MASS 330', 'MASS 334', 'MASS 431', ['MASS 434', 'MASS 436']]]\n",
      "99.59 percent successfully parsed\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    df = data_reader(\"undergraduate\")\n",
    "\n",
    "    # Call the functions to clean the data manually\n",
    "    df = math_manually_cleaned('PreReqText', df)\n",
    "    df = ANTH_manually_cleaned('PreReqText', df)\n",
    "    df = BIO_manually_cleaned('PreReqText', df)\n",
    "    df = CHEM_manually_cleaned('PreReqText', df)\n",
    "    df = CS_manually_cleaned('PreReqText', df)\n",
    "    df = CDIS_manually_cleaned('PreReqText', df)\n",
    "    df = EE_manually_cleaned('PreReqText', df)\n",
    "    df = GEOG_manually_cleaned('PreReqText', df)\n",
    "    df = GEOL_manually_cleaned('PreReqText', df)\n",
    "    df = MATH_manually_cleaned('PreReqText', df)\n",
    "    df = MET_manually_cleaned('PreReqText', df)\n",
    "    df = STAT_manually_cleaned('PreReqText', df)\n",
    "    df = RPLS_manually_cleaned('PreReqText', df)\n",
    "    df = PSYC_manually_cleaned('PreReqText', df)\n",
    "    df = choose_two_manually_cleaned('PreReqText', df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df = or_formatter('PreReqText', df)\n",
    "    df = or_and_formatter_2('PreReqText', df)\n",
    "    df = typo_fixer('PreReqText', df)\n",
    "    df['PreReqText'] = remove_before_strongly_recommended(df['PreReqText'])\n",
    "    df['PreReqText'] = remove_after_point(df['PreReqText'], 'CO-REQUISITE:')\n",
    "    df = parser_function('PreReqText', df)\n",
    "    df = And_formatter_for_separation('PreReqText', df)\n",
    "    df = credit_300('PreReqText', df)\n",
    "    df = create_new_columns(df, largest_comma_count(df))\n",
    "    df = split_values_into_columns(df,largest_comma_count(df))\n",
    "    df = inner_array_split(df)\n",
    "    json_creator(df, \"ParsedData.json\")\n",
    "    json_column(df, \"ParsedData.json\")\n",
    "    df.insert(3, \"Json format\", df.pop(\"Json format\"))\n",
    "    df.to_excel(\"Jsoncolumn.xlsx\")\n",
    "    print(parse_data(\"ParsedData.json\",df))\n",
    "\n",
    "main()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5aa4945d5700b1caf56131d572a98b97881760c88ddbdce6f05585973978b348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
